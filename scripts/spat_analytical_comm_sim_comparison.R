## Purpose: to compare the analytical probability models for the spatial
## abundance distribution with that generated by the community simulator

setwd('~/maxent/spat/scripts')

source('./spat_analytical_prob_funcs.R')
dyn.load('./heap.so')
## generate some comparitive frequency distributions
## example from pg 96 fig 4.1
#pdf('../figs/analytical_prob_funcs.pdf',width=14,height=7)
par(mfrow=c(1,2))
n0 = 112
n = 0:5
A0 = 64
A = 1
out = matrix(NA,nrow=4,ncol=length(n))
out[1,] = binomial_prob(n,A,n0,A0)
out[2,] = laplace_prob(n,A,n0,A0)
out[3,] = sapply(n, function(x) heap_prob(x,A,n0,A0, use_c=TRUE))
out[4,] = neg_bin_prob(n,A,n0,A0)

system('python ./spat_community_generation.py 1 112 500 6 False None S1_N112 &')
comms = read.csv('../comms/simulated_comms_S1_N112_C500_B6_grid.txt')
comms = as.matrix(comms)
## reshape for ease of analysis
Ncomms = 500
Nquads = 64

commMat = matrix(comms[,4],ncol=Ncomms,nrow=Nquads)
filler = matrix(rep(0:max(commMat),each=ncol(commMat)),nrow=max(commMat)+1,byrow=TRUE)
cnts = apply(rbind(commMat,filler),2,table) - 1
freqs = cnts/nrow(commMat)
freqAvg = apply(freqs,1,mean)

plot(n,out[1,],ylim=range(out,na.rm=TRUE),type='n',ylab='Probabiliy',
     main=paste('No = ',n0,', A = Ao/',A0,sep=''))
for(i in 1:3)
  lines(n,out[i,],col=i,type='l',lwd=2)
points(n,out[4,],col=4,pch=19,cex=1.5)
points(0:5,freqAvg[1:6],cex=1.5) ## Matches perfectly with HEAP from Fig 4.1
legend('topright',c('bin','lap','heap','negbin(k=1)','simulator'),
       col=c(1:4,1),lwd=c(rep(3,3),rep(NA,2)),lty=c(rep(1,3),rep(NA,2)),
       pch=c(rep(NA,3),19,1),cex=2,bty='n')
## lap, mete and negbi are equivalent
## heap and meteiter are equivalent

n0 = 5
n = 0:5
A0 = 4
A = 1
out = matrix(NA,nrow=4,ncol=length(n))
out[1,] = binomial_prob(n,A,n0,A0)
out[2,] = laplace_prob(n,A,n0,A0)
out[3,] = sapply(n, function(x) heap_prob(x,A,n0,A0, use_c=TRUE))
out[4,] = neg_bin_prob(n,A,n0,A0)

system('python ./spat_community_generation.py 1 5 500 2 False None S1_N5 &')
comms = read.csv('../comms/simulated_comms_S1_N5_C500_B2_grid.txt')
comms = as.matrix(comms)
## reshape for ease of analysis
Ncomms = 500
Nquads = 4

commMat = matrix(comms[,4],ncol=Ncomms,nrow=Nquads)
filler = matrix(rep(0:max(commMat),each=ncol(commMat)),nrow=max(commMat)+1,byrow=TRUE)
cnts = apply(rbind(commMat,filler),2,table) - 1
freqs = cnts/nrow(commMat)
freqAvg = apply(freqs,1,mean)

plot(n,out[1,],ylim=range(out,na.rm=TRUE),type='n',ylab='Probability',
     main='No = 5, A = Ao/4')
for(i in 1:3)
  lines(n,out[i,],col=i,type='l',lwd=2)
points(n,out[4,],col=4,pch=19,cex=1.5)
points(0:5,freqAvg[1:6],cex=1.5) ## Matches perfectly with HEAP from Fig 4.1
legend('topright',c('bin','lap','heap','negbin(k=1)','simulator'),
       col=c(1:4,1),lwd=c(rep(3,3),rep(NA,2)),lty=c(rep(1,3),rep(NA,2)),
       pch=c(rep(NA,3),19,1),cex=2,bty='n')
## mete and negbi are equivalent
## heap and meteiter are equivalent
#dev.off()

## Examine recursion relationships given for HEAP turnover-----------------------
## Figure 6.8 in Harte 2007 displays a linear relationship between log2 CHI and j
## examine if the recursion relations return this relationship
i = 8
j = 2:5
n0 = 10
chi = sapply(j, function(x) chi_heap(i, x, n0, use_c=TRUE))
plot(j, log2(chi), type='o')
summary(lm(log2(chi) ~ j))
## these definately display a log-linear relationship as depicted in the book 
## chapter

## Now examine the relationship depicted in Figure 6.7 in Harte 2007 if we can
## recreate this figure it is a good check on the algorithims
## first generate results using python (b/c dictionaries are necessary)
system('python spat_chi_heap_examination.py')

chi_dat = read.csv('../sorensen/harte_2007_chi_heap_results.txt')

plot(chi_appr ~ chi, data= chi_dat)
mod = lm(chi_appr ~ chi, data= chi_dat)
abline(mod)
summary(mod)

## that doesn't look quite correct, but multiplying all the values by 2 makes
## it look pretty close to the book chapter

plot(chi_appr ~ chi, data= 2 * chi_dat)
mod = lm(chi_appr ~ chi, data=2 * chi_dat)
abline(mod)
summary(mod)


## Figure 6.8 reproduced exactly, linear regression equation matches!
par(mfrow=c(1,1))
plot(log2(chi) ~ j, data = chi_dat, subset= j < 6 & j > 1 & i == 14,
     ylim=c(-15.4, -13.9), xlim=c(0, 6), pch=15, cex=1.5)
points(log2(chi_appr) ~ j, data=chi_dat, subset= j < 6 & j > 1 & i == 14,
       pch=1)
mod = lm(log2(chi) ~ j, data = chi_dat, subset= j < 6 & j > 1 & i == 14)
abline(mod)
summary(mod)

## this indicates that we have a functioning analytical metric for the binary
## sorensen index. Given the proximity of the quantiative and binary sorensen DDR
## this will likely give us a good approximation of the simulated DDR once it
## is considered in relation to degree of seperation rather than geographic 
## distance

library(vegan)
source('./spat_sim_vario_func.R')

S = 20
abu = matrix(rep(200, S), ncol=S)
write.table(abu, file='../tst_abu.csv', sep=',',
            row.names=FALSE, col.names=FALSE)

system('python ./spat_community_generation.py 20 100 500 8 False ../tst_abu.csv S20_N100 ')
comms = read.csv('../comms/simulated_comms_S20_N100_empirSAD_C500_B8_grid.txt')
comms = as.matrix(comms)
#comms[ , 5] = comms[ , 4]
#comms = read.csv('../comms/simulated_comms_baldmnt_C200_B5_grid.txt')
#comms = as.matrix(comms)

## 3 x 2, i = 3, for j = 1:3, sor_avg should be .6, .5, .5
occ = c(rep(1, 4), rep(c(1,0), 2))
comms = data.frame(comm = 1, 
                   x = rep(1:4, 2),
                   y = rep(1:2, each=4),
                   sp1 = occ,
                   sp2 = occ)
comms = as.matrix(comms)
1 - vario_bisect(comms[, -(1:3)], comms[,2:3], 1:3, 'bray')$var 


## 2 x 2, i = 2 for j = 1:2, sor_avg should be .333, 0 
occ = c(1,0,0,1)
comms = data.frame(comm = 1, 
                   x = rep(1:2, 2),
                   y = rep(1:2, each=2),
                   sp1 = occ,
                   sp2 = occ)
comms = as.matrix(comms)
1 - vario_bisect(comms[, -(1:3)], comms[,2:3], 1:2, 'bray')$var 

##8 x 4, i = 5, for j = 4:5, sor_avg should be .333, .333
occ = c(0, 1, 1, 0, 1, 0, 0, 1,
        0, 0, 0, 0, 1, 1, 1, 1,
        1, 1, 1, 1, 0, 0, 0, 0,
        1, 0, 1, 0, 0, 1, 0, 1)
comms = data.frame(comm = 1, 
                   x = rep(1:8, 4),
                   y = rep(1:4, each=8),
                   sp1 = occ,
                   sp2 = occ)
comms = as.matrix(comms)
1 - vario_bisect(comms[, -(1:3)], comms[,2:3], 4:5, 'bray')$var 

system('python spat_heap_ddr.py 8 8 empirSAD ../tst_abu.csv ../tst_heap_ddr.csv')
heap_ddr = read.csv('../tst_heap_ddr.csv')

sim_ddr1 = matrix(NA, nrow=500, ncol=4)
for(i in 1:500) {
  tmp_comm = comms[comms[,1] == i, ]
  v = vario_bisect(tmp_comm[ , -(1:3)] > 0, 
                   tmp_comm[ , 2:3],
                   distance.metric='bray')
  sim_ddr1 [i, ] = v$vario$var
}
1 - apply(sim_ddr1, 2, mean)
heap_ddr

pdf('../figs/heap_ddr_check_geo_dist_raw.pdf', width=7 *2 , height=7)
  par(mfrow=c(1, 2))
  plot(v$vario$dist * min(heap_ddr$dist), 1 - apply(sim_ddr1, 2, mean), type='o',
       ylim=c(.2, .6), xlim=c(0.05, .8), col='red', xlab='Dist',ylab='Sor',
       pch=19)
  lines(heap_ddr$dist, heap_ddr$sor, col='blue', type='o', pch=19)
  ##
  plot(v$vario$dist * min(heap_ddr$dist), 1 - apply(sim_ddr1, 2, mean), type='o',
       ylim=c(.2, .6), xlim=c(0.05, .8), col='red', xlab='Dist',ylab='Sor',
       log='xy', pch=19)
  lines(heap_ddr$dist, heap_ddr$sor, col='blue', type='o', pch=19)
  legend('topright',c('simul','analy'), col=c('red','blue'),pch=19, lty=1,
         bty='n')
dev.off()


vals = dist_bisect(8)
gdist = dist(vals$crd)
jdist = vals$dist
H = as.vector(round(gdist))
split(gdist, H)
sapply(split(jdist, H), table)
heap_sor = c((4 * heap_ddr$sor[1] + 
              8 * heap_ddr$sor[2] +
              4 * heap_ddr$sor[3])/16, 
             heap_ddr$sor[3], heap_ddr$sor[3])
Dist = sapply(split(gdist, H), mean)

sim_sor2 = matrix(NA, nrow=500, ncol=21)
for(i in 1:500) {
  tmp_comm = comms[comms[,1] == i, ]
  tmp_comm = tmp_comm[order(tmp_comm[,3], tmp_comm[,2]),]
  sim_sor2[i,] = sapply(split(1-vegdist(tmp_comm[,-(1:3)], binary=T),
                         H), mean, na.rm=T)
}
apply(sim_sor2, 2, mean)
heap_sor

  
pdf('../figs/heap_ddr_check_geo_dist.pdf')
  par(mfrow=c(1,1))
  plot(heap_ddr$dist, heap_ddr$sor, type='p', log='xy')
  lines(Dist, apply(sim_sor, 2, mean), type='o', col='red')
  legend('bottomright', c('analytical', 'simulated'), col=c('black', 'red'),
         lty=1, bty='n')
dev.off()

sim_sor - heap_ddr$sor
par(mfrow=c(2, 2))
for(j in seq(1, x-1, 2)) {
  plot(density(sor_mat[ , j], na.rm=T), xlim=c(0, 1))
  abline(v=heap_ddr[heap_ddr$j == j, 3])
}


dyn.load('tgangle.so')
v_vals = array(NA, dim=c(500, 3, 3))
for(i in 1:500){
  tmp_comm = comms[comms[,1] == i, ]
  tmp_comm[ , -(1:3)] = (tmp_comm[ , -(1:3)] > 0) * 1
  ## reorder temp_comm to match coords
  tmp_comm = tmp_comm[order(tmp_comm[, 2], tmp_comm[, 3]), ]
  v = vario(tmp_comm[, -(1:3)], tmp_comm[,2:3],distance.metric='bray')
  v90= vario(tmp_comm[, -(1:3)], tmp_comm[,2:3],distance.metric='bray',
            direction = 90, tolerance=10, unit.angle='degrees')
  v0 = vario(tmp_comm[, -(1:3)], tmp_comm[,2:3],distance.metric='bray',
            direction = 0, tolerance=10, unit.angle='degrees')
  v_vals[i, , ] = rbind(v$vario$exp.var[1:3],
                        v90$vario$exp.var[1:3],
                        v0$vario$exp.var[1:3])
}

boxplot(1-v_vals[, 1, ], ylim=c(.5,.8))
abline(h=sim_sor[1])

par(mfrow=c(1,1))
plot(v$vario$Dist, 1- v$vario$exp.var, type='o', ylim=c(.5,.8), xlim=c(0, 3))
lines(v0$vario$Dist, 1-v0$vario$exp.var, type='o', col='red')
lines(v90$vario$Dist, 1-v90$vario$exp.var, type='o',col='blue')
abline(h=sim_sor[1])
  




## so expected analytical is postive biased which is the direction of 
## difference we expect but the bias appears to be larger than expected
## the difference between the analytical and simulated also slightly
## decreases as distance increases (i.e., j dec).

setwd('~/maxent/spat')

load('./sorensen/empirSorBin.Rdata')
load('./sorensen/simEmpirSorAvg.Rdata')

source('./scripts/spat_sim_vario_func.R')

area = 76.56
obs = empirSorBin$bormann[empirSorBin$bormann$Comm == area, ]
pred = simSorBinAvg$bormann_empirSAD_C200_B12_grid[simSorBinAvg$bormann_empirSAD_C200_B12_grid$Comm == area, ]

dat = read.csv('./sorensen/bormann_empirSAD_mete_sor.csv')
dat_tmp = dat[dat$i == 8, ]
sor_pred = mete_sor_transform(dat_tmp)

nbreaks = read.csv('./data/nbreaks.csv')
breaks = subset(nbreaks, comm == 'bormann' & grain == 3)$nbreaks + 1
log=TRUE
comms = read.csv('./data/bormann_comms.csv')
comms = comms[comms$grain == area, ]
Dist = dist(comms[ , 2:3] * sqrt(area))
hmin = min(Dist)  ## potentially this should be set when breaks is NA as well
maxDist = max(Dist)
hmax = maxDist / 2
H = Dist
breaks = get_breaks(breaks, hmin, hmax, maxDist, log)

for (i in 1:(length(breaks) - 1)) {
  H[H >= breaks[i] & H < breaks[i + 1]] = breaks[i]
}  
H[H < hmin] = NA
H[H > hmax] = NA
H = as.vector(H)
exp.split = split(sor_pred$sor, H)
sor_pred_avg = sapply(exp.split, mean, na.rm=TRUE)
dist_avg = sapply(split(Dist, H), mean, na.rm=TRUE)

crd = dist_bisect(8, use_c=TRUE)$crd

pdf('./figs/compare_mete_predictions.pdf', width=7*2, height=7)
  par(mfrow=c(1,2))
  plot(pred$Dist, pred$Avg, col='red', lwd=2, type='l',
       ylim=c(.23, .5), xlab='Dist', ylab='Sor')
  lines(dist_avg, sor_pred_avg, col='blue', lwd=2)
  lines(dat_tmp$dist, dat_tmp$sor, col='green3', lwd=2)
##
  plot(pred$Dist, pred$Avg, col='red', lwd=2, type='l',
       ylim=c(.23, .5), xlab='Dist', ylab='Sor', log='xy')
  lines(dist_avg, sor_pred_avg, col='blue', lwd=2)
  lines(dat_tmp$dist, dat_tmp$sor, col='green3', lwd=2)
##
  legend('topright', c('sim avg','analytical','analytical transformed'),
         col=c('red','green3', 'blue'), lty=1, bty='n')
dev.off()



### checking chi_heap calculation
i = 2
j = 1
n0 = 3
#
chi_heap(i, j, n0)
#
(n0 + 1) ^ -1 * (calc_lambda(1, 1) * calc_lambda(1, 2) +
                 calc_lambda(1, 2) * calc_lambda(1, 1))
#
(n0 + 1)^-1 * 
  ((1 - ((1 + 1)^-1)) * (1 - ((2 + 1)^-1))) * 2
## those all match
i = 2
j = 2
n0 = 3
chi_heap(i, j, n0)
(n0 + 1) ^ -1 * 
   ( (2 + 1) ^-1 *
       (calc_lambda(0, 1) * calc_lambda(0, 1))
     +
     (3 + 1) ^-1 * 
       (calc_lambda(0, 1) * calc_lambda(0, 2) + 
        calc_lambda(0, 2) * calc_lambda(0, 1))
    )

(n0 + 1) ^-1 * ((2 + 1)^-1 + 2 * (3 + 1)^-1)
## those match too
## from first principles if i = 2 and j = 2
     ##prob of a 2 and 1 bisection
2 * ((3 + 1) ^-1  *
    ((2 + 1)^-1 * (2 + 1)^-1)) + 
2 * ((3 + 1) ^ -1 *
    2 * ((3 + 1)^-1 * (3 + 1)^-1))
chi_heap(2, 2, 3)

## for j = 2






sor_mat = matrix(NA, nrow=500, ncol=nchar(bc[1]))
gdist = NULL
for(j in heap_ddr$j) {
  col_to = x - (x - j + 1)
  #col_to = x - (x - j + 1) + 1
  if (j == x) {
    gd_mat = (as.matrix(dist(bc_mat[ , 1:(col_to - 1)])) == 0) * 1
  #  gd_mat = (as.matrix(dist(bc_mat[ , -col_to])) == 0) * 1
  }
  else if (j == 1) {
      gd_mat = (as.matrix(dist(bc_mat[ , 1])) == 1) * 1
  }
  else {
    gd_mat1 = (as.matrix(dist(bc_mat[ , 1:col_to])) == 0) * 1
    gd_mat2 = (as.matrix(dist(bc_mat[ , col_to + 1])) == 1) * 1
  #  gd_mat1 = (as.matrix(dist(bc_mat[ , -col_to])) == 0) * 1
  #  gd_mat2 = (as.matrix(dist(bc_mat[ , col_to])) == 1) * 1    
    gd_mat = gd_mat1 * gd_mat2
  }
  tr_mat = gd_mat * lower.tri(gd_mat)
  D_geo = as.matrix(dist(coords[, 1:2])) * tr_mat
  gdist[j] = mean(D_geo[D_geo > 0])
  for(i in 1:500) {
    tmp_comm = comms[comms[,1] == i, ] 
    ## reorder temp_comm to match coords
    #intersect(match_index(tmp_comm[, 2], 1), 
    #          match_index(tmp_comm[, 3], 16))
    tmp_comm = tmp_comm[order(tmp_comm[, 2], tmp_comm[, 3]), ]
    sor_dist = 1 - vegdist(tmp_comm[ , -(1:3)] > 0)  
    D_sp = as.matrix(sor_dist) * tr_mat
    sor_mat[i, j] = mean(D_sp[D_geo > 0], na.rm=T)
    #calc_D(8, W=16, rect=F, LW_ratio =1)
  }
}



                 




